# _________________________________Roxygen_________________________________________________________
#' Comparing two samples by measuring their similarity
#'
#' It returns spatial similarity of two data sets with equal number of columns (variables) and any number
#' of rows (observations).
#'
#' @param smpl1 First smaple as a matrix or data frame object
#' @param smpl2 Second sample
#' @param merge_ If two samples must be merged first (default True)
#'
#' @details TBD
#'
#' @return Similarity value
#'
#' @seealso \code{\link{clustering}} for clustering a similarity matrix generated by \code{compare}.
#'
#' @author Morteza H. Chalabi, \url{mor.chalabi@@gmail.com}
#'
#' @examples
#' require(compaRe)
#'
#' rm(list = ls())
#'
#' # Step 1: Reading in fcs files
#'
#' data(package = 'compaRe', list = c('dataset1','dataset2'))
#'
#' # Step 2: Transforming data
#'
#' smpl1[ smpl1 < 0 ] = 0      # negative values in a fcs files are noise
#' smpl1 = log(smpl1+1)        # fcs data are logarithmically distributed
#' smpl2[ smpl2 < 0 ] = 0
#' smpl2 = log(smpl2+1)
#'
#' # Step 3: Comparing (measuring similarity)
#'
#' message(compaRe::compare(smpl1 = smpl1, smpl2 = smpl2, merge_ = TRUE))
#'
#' @export

compare = function(smpl1 = NULL, smpl2 = NULL, merge_ = TRUE)
{
  nrow_1 = nrow(smpl1)
  nrow_2 = nrow(smpl2)
  smpl_ = list(smpl1, smpl2)

  if(merge_)      # if samples should be merged
  {
    # STEP 1: Merging two data sets ####
    message('Merging two data sets')

    barcodes_ = rep(1, nrow(smpl1))
    barcodes_ = as.integer(c(barcodes_, rep(2, nrow(smpl2))))
    smpl_ = do.call(smpl_, what = rbind)
    rm(smpl1, smpl2)

    # STEP 2: Forming hypercubes ####
    message('Forming hypercubes')

    rgns_ = rep(0, nrow(smpl_))
    tot_rgns = 0
    for(d_ in 1:ncol(smpl_))
    {
      dvds_ = quantile(x = smpl_[,d_], probs = c(1/3,2/3))      # tertiles

      if(d_ == 1)
      {
        f_d = rgns_
      }else
      {
        bInfo = rgns_ - tot_rgns
        s_d_1 = bInfo %/% 3^(d_-2)
        f_d_1 = bInfo - s_d_1*3^(d_-2)
        f_d = f_d_1*3 + s_d_1
      }

      # first hypercube in current dimesnion
      rows_ = which(smpl_[,d_] < dvds_[1])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_]
      }

      # second hypercube in current dimesnion
      rows_ = which(dvds_[1] <= smpl_[,d_] & smpl_[,d_] <= dvds_[2])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 3^(d_-1)
      }

      # third hypercube in current dimesnion
      rows_ = which(dvds_[2] < smpl_[,d_])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 2*3^(d_-1)
      }

      tot_rgns = tot_rgns + 3^(d_-1)
    }

    # STEP 3: Denoising ####
    message('Denoising')

    # denoising; removing hypercubes with fewer points than expected
    small_smpl = if(nrow_1 < nrow_2) { nrow_1 }else{ nrow_2 }
    min_pts = if(small_smpl < 200) { ceiling(.1*small_smpl) }else{ 20 }     # minimum number of points in each region
    rgns_sz = as.data.frame(x = table(rgns_), stringsAsFactors = T)         # size of each hypercube (region)
    rgns_sz = rgns_sz[which(min_pts <= rgns_sz$Freq),]
    idxs_ = which(rgns_ %in% rgns_sz$rgns_)
    rgns_ = rgns_[ idxs_ ]                                                  # removing noise regions
    barcodes_ = barcodes_[idxs_]                                            # removing noise data points

    # STEP 4: Extracting hypercubes ####
    message('Extracting hypercubes')

    # ordering smpl_ by region number required for next step
    idxs_ = order(rgns_, decreasing = F)
    rgns_ = rgns_[idxs_]
    barcodes_ = barcodes_[idxs_]
    rgns_ = as.character(rgns_)

    # extracting start of each region (for sake of processing speed)
    rgns_srt = vector(mode = 'list',length = nrow(rgns_sz))     # a vector to keep track of start and end of each region in smpl_
    names(rgns_srt) = rgns_sz$rgns_                             # since rgns_sz is returned by table() it already has unique regions
    rgns_srt[[ rgns_[1] ]] = 1
    for(row_ in 2:length(rgns_))
    {
      if(rgns_[row_] != rgns_[row_-1] )
      {
        rgns_srt[[ rgns_[row_] ]] =  row_
      }
    }
    rgns_srt[['end']] = length(rgns_)+1                         # to mark end of last region

    # STEP 5: Measuring similarity ####
    message('Measuring similarity')

    dissim_ = numeric(length = length(rgns_srt))      # a vetor containing dissimilarity in each hypercube
    for(j_ in 1:(length(rgns_srt)-1))                 # last element of rgns_srt keeps end of last region, so 1 must be removed
    {
      idxs_ = rgns_srt[[j_]]:(rgns_srt[[j_+1]]-1)     # start and end of current region in smpl_
      bcs_in_rgn = barcodes_[idxs_]                   # barcodes of observations in this region

      n_1 = length(which(bcs_in_rgn %in% 1))
      n_2 = length(idxs_) - n_1

      por_1 = n_1/nrow_1                              # portion of data points from sample #1 in current hypercube
      por_2 = n_2/nrow_2

      if(por_1 == 0 | por_2 == 0)                     # if one sample is absent in this hypercube, dissimilarity is 100%
      {
        dissim_[j_] = 1
      }else
      {
        dissim_[j_] = abs(por_1 - por_2)
      }
    }
    simScore_ = (1-mean(dissim_))*100

    return(simScore_)
  }else                     # if samples should not be merged
  {
    rm(smpl1, smpl2)
    rgns_srt_end_smpls = list()
    i_ = 1
    for(smpl_i in smpl_)
    {
      # STEP 1: Forming hypercubes ####
      message('Forming hypercubes')

      rgns_ = rep(0, nrow(smpl_i))
      tot_rgns = 0
      for(d_ in 1:ncol(smpl_i))
      {
        dvds_ = quantile(x = smpl_i[,d_], probs = c(1/3,2/3))      # tertiles

        if(d_ == 1)
        {
          f_d = rgns_
        }else
        {
          bInfo = rgns_ - tot_rgns
          s_d_1 = bInfo %/% 3^(d_-2)
          f_d_1 = bInfo - s_d_1*3^(d_-2)
          f_d = f_d_1*3 + s_d_1
        }

        # first hypercube in current dimesnion
        rows_ = which(smpl_i[,d_] < dvds_[1])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_]
        }

        # second hypercube in current dimesnion
        rows_ = which(dvds_[1] <= smpl_i[,d_] & smpl_i[,d_] <= dvds_[2])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 3^(d_-1)
        }

        # third hypercube in current dimesnion
        rows_ = which(dvds_[2] < smpl_i[,d_])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 2*3^(d_-1)
        }

        tot_rgns = tot_rgns + 3^(d_-1)
      }

      # STEP 2: Denoising ####
      message('Denoising')

      # denoising; removing hypercubes with fewer points than expected
      min_pts = if(nrow(smpl_i) < 200) { ceiling(.1*nrow(smpl_i)) }else{ 20 }     # minimum number of points in each region
      rgns_sz = as.data.frame(x = table(rgns_), stringsAsFactors = T)             # size of each hypercube (region)
      rgns_sz = rgns_sz[which(min_pts <= rgns_sz$Freq),]
      idxs_ = which(rgns_ %in% rgns_sz$rgns_)
      rgns_ = rgns_[ idxs_ ]                                                      # removing noise regions

      # STEP 3: Extracting hypercubes ####
      message('Extracting hypercubes')

      # ordering regions descendingly required for next step
      idxs_ = order(rgns_)
      rgns_ = rgns_[idxs_]
      rgns_ = as.character(rgns_)

      # extracting start and end of each region (for sake of processing speed)

      rgns_srt_end = vector(mode = 'list',length = nrow(rgns_sz))     # a vector to keep track of start and end of each region in smpl_
      names(rgns_srt_end) = rgns_sz$rgns_                             # since rgns_sz is returned by table() it already has unique regions
      rgns_srt_end[[ rgns_[1] ]]$srt = 1
      for(row_ in 2:length(rgns_))
      {
        if(rgns_[row_] != rgns_[row_-1])
        {
          rgns_srt_end[[ rgns_[row_-1] ]]$end = row_-1
          rgns_srt_end[[ rgns_[row_] ]]$srt = row_
        }
      }
      rgns_srt_end[[ rgns_[length(rgns_)] ]]$end = length(rgns_)      # to mark end of last region
      rgns_srt_end_smpls[[i_]] = rgns_srt_end
      i_ = i_ + 1
    }

    # STEP 4: Measuring similarity ####
    message('Measuring similarity')

    all_rgns = union(names(rgns_srt_end_smpls[[1]]), names(rgns_srt_end_smpls[[2]]))      # union of all hypercubes in both samples
    dissim_ = numeric(length = length(all_rgns))                                          # a vetor containing dissimilarity in each hypercube
    j_ = 1                                                                                # a counter for dissim_
    for(rgn_ in all_rgns)
    {
      n_1 = rgns_srt_end_smpls[[1]][[rgn_]]$end-rgns_srt_end_smpls[[1]][[rgn_]]$srt+1
      if(length(n_1) == 0) { n_1 = 0}
      n_2 = rgns_srt_end_smpls[[2]][[rgn_]]$end-rgns_srt_end_smpls[[2]][[rgn_]]$srt+1
      if(length(n_2) == 0) { n_2 = 0}
      por_1 = n_1/nrow_1     # portion of data points from sample #1 in current hypercube
      por_2 = n_2/nrow_2

      if(por_1 == 0 | por_2 == 0)
      {
        dissim_[j_] = 1
      }else
      {
        dissim_[j_] = abs(por_1 - por_2)
      }

      j_ = j_+1
    }
    simScore_ = (1-mean(dissim_))*100

    return(simScore_)
  }
}


