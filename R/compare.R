# _________________________________Roxygen_________________________________________________________
#' Comparing two samples by measuring their similarity
#'
#' It returns spatial similarity of two data sets with equal number of columns (variables) and any number
#' of rows (observations).
#'
#' @param smpl1 First smaple as a matrix or data frame object
#' @param smpl2 Second sample
#' @param merge_ If two samples must be merged first (default True)
#'
#' @details TBD
#'
#' @return Similarity value
#'
#' @seealso \code{\link{clustering}} for clustering a similarity matrix generated by \code{compare}.
#'
#' @author Morteza H. Chalabi, \url{mor.chalabi@@gmail.com}
#'
#' @examples
#' require(compaRe)
#'
#' rm(list = ls())
#'
#' # Step 1: Reading in fcs files
#'
#' data(package = 'compaRe', list = c('dataset1','dataset2'))
#'
#' # Step 2: Transforming data
#'
#' smpl1[ smpl1 < 0 ] = 0      # negative values in a fcs files are noise
#' smpl1 = log(smpl1+1)        # fcs data are logarithmically distributed
#' smpl2[ smpl2 < 0 ] = 0
#' smpl2 = log(smpl2+1)
#'
#' # Step 3: Comparing (measuring similarity)
#'
#' compaRe::compare(smpl1 = smpl1, smpl2 = smpl2, merge_ = TRUE)
#'
#' @export

compare = function(smpl1 = NULL, smpl2 = NULL, merge_ = TRUE)
{
  nrow_1 = nrow(smpl1)
  nrow_2 = nrow(smpl2)
  smpl_ = list(smpl1, smpl2)

  if(merge_)      # if samples should be merged
  {
    # STEP 1: Merging two data sets ####
    message('Merging two data sets')

    barcodes_ = rep(1, nrow(smpl1))
    barcodes_ = as.integer(c(barcodes_, rep(2, nrow(smpl2))))
    smpl_ = do.call(smpl_, what = rbind)
    rm(smpl1, smpl2)

    # STEP 2: Forming hypercubes ####
    message('Forming hypercubes')

    rgns_ = rep(0, nrow(smpl_))
    tot_rgns = 0
    for(d_ in 1:ncol(smpl_))
    {
      dvds_ = quantile(x = smpl_[,d_], probs = c(1/3,2/3))      # tertiles

      if(d_ == 1)
      {
        f_d = rgns_
      }else
      {
        bInfo = rgns_ - tot_rgns
        s_d_1 = bInfo %/% 3^(d_-2)
        f_d_1 = bInfo - s_d_1*3^(d_-2)
        f_d = f_d_1*3 + s_d_1
      }

      # first hypercube in current dimesnion
      rows_ = which(smpl_[,d_] < dvds_[1])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_]
      }

      # second hypercube in current dimesnion
      rows_ = which(dvds_[1] <= smpl_[,d_] & smpl_[,d_] <= dvds_[2])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 3^(d_-1)
      }

      # third hypercube in current dimesnion
      rows_ = which(dvds_[2] < smpl_[,d_])
      if( 0 < length(rows_))
      {
        rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 2*3^(d_-1)
      }

      tot_rgns = tot_rgns + 3^(d_-1)
    }

    # STEP 3: Extracting regions ####
    message('Optimization')

    # ordering smpl_ by region number
    idxs_ = order(rgns_)
    rgns_ = rgns_[idxs_]
    barcodes_ = barcodes_[idxs_]
    smpl_ = smpl_[idxs_,]

    # extracting start and end of each region (for sake of processing speed)
    rgns_ = as.character(rgns_)
    uniq_rgns = unique(rgns_)
    rgns_srt_end = matrix(data = NA, nrow = length(uniq_rgns), ncol = 2)
    rownames(rgns_srt_end) = uniq_rgns
    colnames(rgns_srt_end) = c('srt','end')

    rgns_srt_end[ rgns_[1], "srt" ] = 1
    rgns_srt_end[ rgns_[length(rgns_)], 'end'] = length(rgns_)
    for(row_ in 2:length(rgns_))
    {
      if(rgns_[row_] != rgns_[row_-1] )
      {
        rgns_srt_end[ rgns_[row_-1], "end"] = row_-1
        rgns_srt_end[ rgns_[row_], "srt"] =  row_
      }
    }

    # STEP 4: Measuiring similarity ####
    message('Computing similarity')

    dissim_ = numeric(length = nrow(rgns_srt_end))      # a vetor containing dissimilarity in each hypercube
    for(j_ in 1:nrow(rgns_srt_end))
    {
      idxs_ = rgns_srt_end[j_,'srt']:rgns_srt_end[j_,'end']     # start and end of current region in smpl_
      bcs_in_rgn = barcodes_[idxs_]       # barcodes of observations in this region

      n_1 = length(which(bcs_in_rgn %in% 1))
      n_2 = length(idxs_) - n_1

      por_1 = n_1/nrow_1                  # portion of data points from sample #1 in current hypercube
      por_2 = n_2/nrow_2

      if(por_1 == 0 | por_2 == 0)         # if one sample is absent in this hypercube, dissimilarity is 100%
      {
        dissim_[j_] = 1
      }else
      {
        dissim_[j_] = abs(por_1 - por_2)
      }
    }
    simScore_ = (1-mean(dissim_))*100

    return(simScore_)
  }else                     # if samples should not be merged
  {
    rm(smpl1, smpl2)
    rgns_srt_end_smpls = list()
    i_ = 1
    for(smpl_i in smpl_)
    {
      # STEP 1: Forming hypercubes ####
      message('Forming hypercubes')

      rgns_ = rep(0, nrow(smpl_i))
      tot_rgns = 0
      for(d_ in 1:ncol(smpl_i))
      {
        dvds_ = quantile(x = smpl_i[,d_], probs = c(1/3,2/3))      # tertiles

        if(d_ == 1)
        {
          f_d = rgns_
        }else
        {
          bInfo = rgns_ - tot_rgns
          s_d_1 = bInfo %/% 3^(d_-2)
          f_d_1 = bInfo - s_d_1*3^(d_-2)
          f_d = f_d_1*3 + s_d_1
        }

        # first hypercube in current dimesnion
        rows_ = which(smpl_i[,d_] < dvds_[1])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_]
        }

        # second hypercube in current dimesnion
        rows_ = which(dvds_[1] <= smpl_i[,d_] & smpl_i[,d_] <= dvds_[2])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 3^(d_-1)
        }

        # third hypercube in current dimesnion
        rows_ = which(dvds_[2] < smpl_i[,d_])
        if( 0 < length(rows_))
        {
          rgns_[rows_] = (tot_rgns + 3^(d_-1)) + f_d[rows_] + 2*3^(d_-1)
        }

        tot_rgns = tot_rgns + 3^(d_-1)
      }

      # STEP 2: Extracting regions ####
      message('Optimization')

      # ordering smpl_i by region number
      idxs_ = order(rgns_)
      rgns_ = rgns_[idxs_]
      smpl_i = smpl_i[idxs_,]

      # extracting start and end of each region (for sake of processing speed)
      rgns_ = as.character(rgns_)
      uniq_rgns = unique(rgns_)
      rgns_srt_end = matrix(data = NA, nrow = length(uniq_rgns), ncol = 2)
      rownames(rgns_srt_end) = uniq_rgns
      colnames(rgns_srt_end) = c('srt','end')

      rgns_srt_end[ rgns_[1], "srt" ] = 1
      rgns_srt_end[ rgns_[length(rgns_)], 'end'] = length(rgns_)
      for(row_ in 2:length(rgns_))
      {
        if(rgns_[row_] != rgns_[row_-1] )
        {
          rgns_srt_end[ rgns_[row_-1], "end"] = row_-1
          rgns_srt_end[ rgns_[row_], "srt"] =  row_
        }
      }
      rgns_srt_end_smpls[[i_]] = rgns_srt_end
      i_ = i_ + 1
    }

    # STEP 3: Measuiring similarity ####
    message('Computing similarity')

    all_rgns = union(rownames(rgns_srt_end_smpls[[1]]), rownames(rgns_srt_end_smpls[[2]]))
    dissim_ = numeric(length = length(all_rgns))      # a vetor containing dissimilarity in each hypercube
    j_ = 1
    for(rgn_ in all_rgns)
    {
      n_1 = tryCatch(expr = rgns_srt_end_smpls[[1]][rgn_,"end"]-rgns_srt_end_smpls[[1]][rgn_,"srt"]+1, error = function(er_) { return(0) })
      n_2 = tryCatch(expr = rgns_srt_end_smpls[[2]][rgn_,"end"]-rgns_srt_end_smpls[[2]][rgn_,"srt"]+1, error = function(er_) { return(0) })
      por_1 = n_1/nrow_1      # portion of data points from sample #1 in current hypercube
      por_2 = n_2/nrow_2

      if(por_1 == 0 | por_2 == 0)
      {
        dissim_[j_] = 1
      }else
      {
        dissim_[j_] = abs(por_1 - por_2)
      }

      j_ = j_ + 1
    }
    simScore_ = (1-mean(dissim_))*100

    return(simScore_)
  }
}


